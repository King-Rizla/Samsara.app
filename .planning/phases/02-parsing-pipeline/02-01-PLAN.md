---
phase: 02-parsing-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - python-src/requirements.txt
  - python-src/parsers/__init__.py
  - python-src/parsers/base.py
  - python-src/parsers/pdf_parser.py
  - python-src/parsers/docx_parser.py
  - python-src/main.py
  - python-src/samsara.spec
autonomous: true

must_haves:
  truths:
    - "PDF files can be parsed and raw text extracted"
    - "DOCX files can be parsed and raw text extracted"
    - "Multi-column PDF layouts are detected and handled"
    - "Tables in PDFs are extracted with structure preserved"
    - "Parsing completes in under 1 second for typical CVs"
  artifacts:
    - path: "python-src/parsers/pdf_parser.py"
      provides: "PDF extraction with PyMuPDF + pdfplumber fallback"
      exports: ["parse_pdf"]
    - path: "python-src/parsers/docx_parser.py"
      provides: "DOCX extraction with python-docx"
      exports: ["parse_docx"]
    - path: "python-src/parsers/base.py"
      provides: "Parser interface and document detection"
      exports: ["parse_document", "DocumentType"]
  key_links:
    - from: "python-src/main.py"
      to: "python-src/parsers/base.py"
      via: "parse_document action handler"
      pattern: "from parsers.base import parse_document"
---

<objective>
Implement document parsers for PDF and DOCX files with intelligent fallback strategies.

Purpose: Extract raw text with structure from CVs, handling complex layouts (two-column, tables) that cause standard extractors to produce jumbled text. This is the foundation for entity extraction in Plan 02-02.

Output: Parser modules that accept a file path and return structured text with layout information. IPC handler for `parse_document` action.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-parsing-pipeline/02-RESEARCH.md
@.planning/phases/02-parsing-pipeline/02-CONTEXT.md
@.planning/phases/01-foundation-distribution/01-03-SUMMARY.md
@python-src/main.py
@python-src/samsara.spec
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add parsing libraries to requirements and update PyInstaller spec</name>
  <files>python-src/requirements.txt, python-src/samsara.spec</files>
  <action>
    Add parsing libraries to requirements.txt:
    - PyMuPDF==1.26.7 (import as `pymupdf`, not `fitz` - fitz is deprecated)
    - python-docx==1.2.0
    - pdfplumber==0.11.9
    - python-dateutil>=2.9.0

    Update samsara.spec to include any needed hidden imports for PyMuPDF and pdfplumber.
    PyMuPDF may need hiddenimports for fitz compatibility and pdfplumber uses Pillow.

    After updating requirements, install them in the venv to verify they install correctly.
  </action>
  <verify>
    Run in python-src venv:
    - `pip install -r requirements.txt` succeeds
    - `python -c "import pymupdf; print(pymupdf.version)"` outputs version
    - `python -c "from docx import Document; print('ok')"` outputs ok
    - `python -c "import pdfplumber; print('ok')"` outputs ok
  </verify>
  <done>All parsing libraries installed and importable, spec updated with hidden imports</done>
</task>

<task type="auto">
  <name>Task 2: Create PDF and DOCX parsers with cascading extraction</name>
  <files>python-src/parsers/__init__.py, python-src/parsers/base.py, python-src/parsers/pdf_parser.py, python-src/parsers/docx_parser.py</files>
  <action>
    Create parsers/ directory with __init__.py.

    **base.py:** Define DocumentType enum (PDF, DOCX, DOC, UNKNOWN), parse_document() dispatcher that detects file type by extension and routes to appropriate parser. Include ParseResult TypedDict with: raw_text, blocks (list of text blocks with bbox), tables (extracted tables), warnings, parse_time_ms.

    **pdf_parser.py:**
    - Use `import pymupdf` (NOT `import fitz`)
    - Implement cascading strategy per RESEARCH.md:
      1. Fast extraction with PyMuPDF get_text("dict", sort=True)
      2. Detect multi-column layout by analyzing block X positions (gap > 100px = multi-column)
      3. For multi-column: process columns separately, merge in reading order
      4. Detect tables with page.find_tables()
      5. If tables found, use pdfplumber for table extraction
    - Check for encrypted/secured PDFs before extraction
    - Return ParseResult with timing

    **docx_parser.py:**
    - Use python-docx Document class
    - Extract paragraphs with style info (heading detection)
    - Extract tables as list of rows
    - Return ParseResult with timing

    For DOC (legacy): Return error message suggesting user save as DOCX. DOC support is deferred per RESEARCH.md open questions.
  </action>
  <verify>
    Create a simple test script that:
    - Parses a sample PDF (use any available PDF or create a simple one)
    - Parses a sample DOCX (create one with python-docx or use available)
    - Prints extracted text and timing
    - Verifies parse_time_ms < 1000 for simple documents
  </verify>
  <done>PDF and DOCX parsers return structured text with layout info, multi-column detection works, tables extracted</done>
</task>

<task type="auto">
  <name>Task 3: Integrate parsers with IPC handler</name>
  <files>python-src/main.py</files>
  <action>
    Add new action handler for 'parse_document' in main.py:
    - Import parse_document from parsers.base
    - Accept request with { action: 'parse_document', id: string, file_path: string }
    - Call parse_document(file_path)
    - Return { id, success: true/false, data: ParseResult } or { id, success: false, error: string }

    Handle errors gracefully:
    - File not found
    - Unsupported file type
    - Encrypted PDF
    - Parse errors

    Ensure response is JSON-serializable (convert any non-serializable types).
  </action>
  <verify>
    Test via stdin/stdout simulation:
    - Start main.py
    - Send: {"action": "parse_document", "id": "test1", "file_path": "path/to/test.pdf"}
    - Verify response has success: true and data.raw_text is populated
    - Send: {"action": "parse_document", "id": "test2", "file_path": "nonexistent.pdf"}
    - Verify response has success: false and error message
  </verify>
  <done>IPC handler accepts parse_document action and returns structured parse results</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Run `pip install -r requirements.txt` in python-src/.venv - all dependencies install
2. Run `python -c "from parsers.base import parse_document; print('ok')"` - imports work
3. Test PDF parsing on a real CV PDF if available, or create a simple test PDF
4. Test DOCX parsing on a real CV DOCX if available, or create a simple test DOCX
5. Verify parse times are under 1 second for typical documents
6. Start main.py and test parse_document action via stdin
</verification>

<success_criteria>
- PDF files parse with raw text, blocks, and tables extracted
- DOCX files parse with raw text and paragraphs extracted
- Multi-column PDFs detected and handled (not jumbled text)
- Parse time < 1 second for typical CVs
- IPC handler responds to parse_document action
- Encrypted/secured PDFs return clear error message
- DOC files return "save as DOCX" message
</success_criteria>

<output>
After completion, create `.planning/phases/02-parsing-pipeline/02-01-SUMMARY.md`
</output>
