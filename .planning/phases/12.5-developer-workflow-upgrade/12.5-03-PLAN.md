# Plan 12.5-03: Multi-Agent Infrastructure & Documentation

## Objective

Configure parallel agent workflows (Claude Code Agent Teams, git worktrees), install GitHub Apps for automated review, and create a reference document capturing the full developer workflow setup.

## Tasks

### 1. Enable Claude Code Agent Teams

- Add to shell profile: `export CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1`
- Verify Agent Teams activate (one session as lead, spawns teammates)
- Test with a simple parallel task on Samsara codebase
- Note: uses ~7x tokens vs standard sessions — use judiciously

### 2. Set Up Git Worktrees for Parallel Work

- Create worktree structure for running agents on separate branches:
  ```
  git worktree add ../Samsara-agent-1 -b agent/feature-1
  git worktree add ../Samsara-agent-2 -b agent/feature-2
  ```
- Install VS Code Git Worktrees extension for easy management
- Test: run Claude Code in main repo AND a worktree simultaneously
- Document worktree conventions (naming, cleanup)

### 3. Install GitHub Apps for Automated Review

- **CodeRabbit** — Install from GitHub Marketplace for automated PR review
  - Configure review depth and focus areas
  - Test with a sample PR
- **GitHub Copilot Agent** (if available) — Enable issue assignment to AI
- Evaluate: pick the tools that add value without noise

### 4. Multi-Project Parallel Workflow Test

- Open Warp with multiple tabs/panes
- Run concurrent sessions on different projects:
  - Tab 1: Claude Code on Samsara (main)
  - Tab 2: Droid on Samsara (worktree branch)
  - Tab 3: Agent on a separate project
- Verify no interference between sessions
- Document the workflow pattern

### 5. Create Reference Document

Write `.planning/references/developer-workflow.md` covering:

- **Tool inventory:** Warp, Factory CLI, GitHub Apps installed
- **Launch configurations:** How to start the Samsara dev environment
- **Multi-agent patterns:**
  - When to use Claude Code vs Factory Droid vs GitHub Copilot
  - Leader/Worker pattern for complex tasks
  - Opus for planning, Sonnet/Haiku for execution
- **Worktree conventions:** Naming, branch strategy, cleanup
- **Cost management:** Token budgets, model selection guidelines
- **Troubleshooting:** Known issues (Warp CPU spikes, Agent Teams token overhead)

## Success Criteria

- [ ] Agent Teams env var configured and verified
- [ ] Git worktrees created and tested with parallel Claude Code sessions
- [ ] At least one GitHub App (CodeRabbit or equivalent) installed and generating reviews
- [ ] Parallel multi-project workflow tested successfully
- [ ] `.planning/references/developer-workflow.md` documents the complete setup

## Notes

- Keep 3-4 specialized agents max — more decreases productivity
- Writer/Reviewer pattern: one Claude writes, another reviews (prevents confirmation bias)
- Every mistake becomes a rule — encode learnings in CLAUDE.md
- Claude Squad (smtg-ai/claude-squad) is an alternative to manual tab management if needed
