---
phase: 12-system-audio-transcription
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - python-src/audio/__init__.py
  - python-src/audio/capture.py
  - python-src/audio/recorder.py
  - python-src/main.py
  - python-src/requirements.txt
  - src/main/audioRecordingService.ts
  - src/main/database.ts
  - src/main/index.ts
  - src/main/preload.ts
autonomous: true

must_haves:
  truths:
    - "Python sidecar can capture system audio (WASAPI loopback) and microphone simultaneously"
    - "Audio streams are mixed into a single mono 16kHz WAV file"
    - "Recording can be started and stopped via IPC from Electron main process"
    - "Audio level data flows from Python to Electron for UI visualization"
  artifacts:
    - path: "python-src/audio/capture.py"
      provides: "DualStreamCapture class with WASAPI loopback + mic"
      min_lines: 80
    - path: "python-src/audio/recorder.py"
      provides: "RecordingSession state machine (idle, recording, stopped)"
      min_lines: 50
    - path: "src/main/audioRecordingService.ts"
      provides: "IPC handlers for recording lifecycle"
      exports: ["startRecording", "stopRecording", "getRecordingState"]
  key_links:
    - from: "src/main/audioRecordingService.ts"
      to: "python-src/main.py"
      via: "sendToPython with start_recording/stop_recording actions"
      pattern: "sendToPython.*start_recording|stop_recording"
    - from: "python-src/audio/capture.py"
      to: "WAV file output"
      via: "wave.open + numpy mixing"
      pattern: "wave\\.open.*wb"
---

<objective>
Create Python sidecar audio capture module and Electron IPC layer for WASAPI loopback + microphone recording.

Purpose: Enable recruiters to record their own calls by capturing both system audio (remote party via WASAPI loopback) and microphone (recruiter voice), mixed into a single file suitable for transcription.

Output: Python audio/ module with dual-stream capture, recording state machine, IPC handlers in Electron main process, database migration v10 for transcription status tracking.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-system-audio-transcription/12-RESEARCH.md
@.planning/phases/12-system-audio-transcription/12-CONTEXT.md
@src/main/pythonManager.ts
@python-src/main.py
@src/main/database.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Python audio capture module with WASAPI loopback + mic</name>
  <files>
    python-src/audio/__init__.py
    python-src/audio/capture.py
    python-src/audio/recorder.py
    python-src/requirements.txt
  </files>
  <action>
Create `python-src/audio/` directory with dual-stream audio capture.

**python-src/audio/**init**.py:**

```python
from .capture import DualStreamCapture
from .recorder import RecordingSession
```

**python-src/audio/capture.py:**
Implement DualStreamCapture class following the pattern from RESEARCH.md:

- Use pyaudiowpatch for WASAPI loopback capture (system audio)
- Open standard PyAudio stream for microphone input
- Store frames with source label ('loopback' or 'mic') in thread-safe list
- Resample loopback audio from device sample rate to 16kHz (Whisper requirement)
- Mix frames by averaging (convert to float32, average, clip to int16 range)
- Save mixed audio as mono 16kHz WAV using wave stdlib
- Provide level_callback for real-time audio level reporting to UI
- Handle graceful fallback if no loopback device found (mic-only mode)

Key implementation details:

- CHUNK = 1024, FORMAT = paInt16, CHANNELS = 1, RATE = 16000
- Use stream_callback mode (non-blocking) for both streams
- Discover devices in **init** using p.get_default_wasapi_loopback() and p.get_default_input_device_info()
- Linear resampling via numpy.interp for sample rate conversion

**python-src/audio/recorder.py:**
Implement RecordingSession class:

- State machine: idle -> recording -> stopped
- start() method creates session ID, output path, calls DualStreamCapture.start_recording()
- stop() method calls DualStreamCapture.stop_recording(), returns audio file path
- get_state() returns current state, session ID, duration
- cleanup() method for resource release

**python-src/requirements.txt:**
Add pyaudiowpatch and faster-whisper (transcription used in Plan 02):

```
pyaudiowpatch>=0.2.13
faster-whisper>=1.2.0
```

DO NOT change existing requirements, only append new ones.
</action>
<verify>
Run `cd python-src && python -c "from audio import DualStreamCapture, RecordingSession; print('Import OK')"` - should print "Import OK" without errors.
</verify>
<done>
Python audio module exists with DualStreamCapture and RecordingSession classes. Can capture from WASAPI loopback and mic, mix to 16kHz mono WAV.
</done>
</task>

<task type="auto">
  <name>Task 2: Add recording actions to Python sidecar main loop</name>
  <files>
    python-src/main.py
  </files>
  <action>
Add recording handlers to main.py's handle_request function.

Import the audio module at top:

```python
from audio import DualStreamCapture, RecordingSession
```

Initialize RecordingSession as module-level singleton (lazy, created on first use):

```python
recording_session = None
```

Add handlers for these actions:

**start_recording:**

- Parameters: output_path (where to save WAV)
- Create RecordingSession if None, call start(output_path)
- Return success with session_id
- Stream level updates via stdout as `{"type": "level", "loopback": 0.5, "mic": 0.3}` (implement level_callback that prints JSON)

**stop_recording:**

- Call recording_session.stop()
- Return success with audio_path and duration_ms

**get_recording_state:**

- Return current state (idle/recording/stopped), session_id if active, duration_ms

**check_audio_devices:**

- Create temporary DualStreamCapture, check if loopback_device and mic_device are available
- Return {loopback_available: bool, mic_available: bool, loopback_device: string, mic_device: string}

Handle exceptions gracefully - if pyaudiowpatch not installed or no audio devices, return error with helpful message.
</action>
<verify>
Run `cd python-src && python -c "import main; print('Main imports audio OK')"` should succeed without ImportError.
</verify>
<done>
Python sidecar handles start_recording, stop_recording, get_recording_state, check_audio_devices actions.
</done>
</task>

<task type="auto">
  <name>Task 3: Create Electron audio recording service and IPC handlers</name>
  <files>
    src/main/audioRecordingService.ts
    src/main/database.ts
    src/main/index.ts
    src/main/preload.ts
  </files>
  <action>
**src/main/audioRecordingService.ts (NEW):**
Create recording service that manages recording lifecycle via Python sidecar.

```typescript
import { app } from "electron";
import * as path from "path";
import * as fs from "fs";
import { sendToPython } from "./pythonManager";
import { getDatabase } from "./database";
import crypto from "crypto";

type RecordingState = "idle" | "recording" | "stopped" | "attaching";

interface RecordingSession {
  id: string;
  state: RecordingState;
  startedAt: string;
  stoppedAt?: string;
  audioPath?: string;
  durationMs?: number;
}

let currentSession: RecordingSession | null = null;
let levelCallback:
  | ((levels: { loopback: number; mic: number }) => void)
  | null = null;
```

Implement these exported functions:

**startRecording():**

- Generate session ID (crypto.randomUUID)
- Create audio path in temp dir: `path.join(app.getPath("temp"), "samsara-recordings", `recording-${sessionId}.wav`)`
- Call sendToPython with action: "start_recording", output_path
- Set currentSession state to "recording"
- Return { success: true, sessionId }

**stopRecording():**

- Verify state is "recording"
- Call sendToPython with action: "stop_recording"
- Update currentSession state to "stopped", capture duration
- Return { success: true, sessionId, durationMs, audioPath }

**getRecordingState():**

- Return current state, sessionId, duration if recording/stopped

**attachRecording(candidateId, projectId):**

- Verify state is "stopped"
- Create call_record in database with type='recruiter', status='pending_transcription'
- Store recording_path in call_record
- Queue transcription (actual transcription in Plan 02)
- Reset currentSession to null
- Return { success: true, callRecordId }

**discardRecording():**

- Delete audio file if exists
- Reset currentSession to null

**checkAudioDevices():**

- Call sendToPython with action: "check_audio_devices"
- Return device availability info

**setLevelCallback(callback):**

- Store callback for level updates (called from main loop on level messages)

**src/main/database.ts:**
Add migration v10 after the existing v9 migration block:

```sql
-- Migration v10: Recruiter recording support
ALTER TABLE call_records ADD COLUMN transcription_status TEXT DEFAULT NULL;
-- Values: NULL, 'queued', 'processing', 'completed', 'failed'
ALTER TABLE call_records ADD COLUMN transcription_error TEXT DEFAULT NULL;
```

Check if columns exist before adding (idempotent migration pattern).

**src/main/index.ts:**
Register IPC handlers:

- "start-recording" -> calls startRecording()
- "stop-recording" -> calls stopRecording()
- "get-recording-state" -> calls getRecordingState()
- "attach-recording" -> calls attachRecording(candidateId, projectId)
- "discard-recording" -> calls discardRecording()
- "check-audio-devices" -> calls checkAudioDevices()

Add level message handling in the Python output parser (pythonManager already has line handling - add check for type: "level" messages and forward to levelCallback).

**src/main/preload.ts:**
Expose recording APIs to renderer:

```typescript
startRecording: () => ipcRenderer.invoke("start-recording"),
stopRecording: () => ipcRenderer.invoke("stop-recording"),
getRecordingState: () => ipcRenderer.invoke("get-recording-state"),
attachRecording: (candidateId: string, projectId: string) =>
  ipcRenderer.invoke("attach-recording", candidateId, projectId),
discardRecording: () => ipcRenderer.invoke("discard-recording"),
checkAudioDevices: () => ipcRenderer.invoke("check-audio-devices"),
```

  </action>
  <verify>
Run `npm run typecheck` - should pass with no errors in audioRecordingService.ts or related files.
  </verify>
  <done>
Electron main process has audioRecordingService.ts with full IPC layer. Recording lifecycle flows from renderer -> main -> Python sidecar. Database has migration v10 for transcription status.
  </done>
</task>

</tasks>

<verification>
1. Python imports work: `cd python-src && python -c "from audio import DualStreamCapture, RecordingSession"`
2. TypeScript compiles: `npm run typecheck`
3. Database migration v10 applied: Check user_version pragma is 10 after app start
4. IPC handlers registered: Search index.ts for "start-recording" handler
</verification>

<success_criteria>

- Python audio/ module captures WASAPI loopback + mic, mixes to 16kHz mono WAV
- Electron audioRecordingService.ts manages recording lifecycle via IPC
- Database has transcription_status and transcription_error columns
- Recording state flows correctly: idle -> recording -> stopped -> idle
  </success_criteria>

<output>
After completion, create `.planning/phases/12-system-audio-transcription/12-01-SUMMARY.md`
</output>
