---
phase: 11-ai-voice-screening
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/main/voiceService.ts
  - src/main/voicePoller.ts
  - src/main/workflowMachine.ts
  - src/main/credentialManager.ts
  - src/main/database.ts
  - src/main/index.ts
  - src/main/preload.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "System can initiate outbound calls via ElevenLabs Conversational AI + Twilio"
    - "Call status and transcripts are retrieved via polling (desktop app constraint)"
    - "Workflow machine triggers voice service when entering screening state"
    - "ElevenLabs credentials are stored securely via safeStorage"
  artifacts:
    - path: "src/main/voiceService.ts"
      provides: "ElevenLabs API client, outbound call initiation, dynamic variables"
      exports: ["initiateScreeningCall", "getCallStatus"]
    - path: "src/main/voicePoller.ts"
      provides: "Polling loop for call status and transcripts"
      exports: ["startVoicePoller", "stopVoicePoller"]
    - path: "src/main/database.ts"
      provides: "Migration v9 with screening_scripts table and call_records columns"
      contains: "screening_scripts"
  key_links:
    - from: "src/main/workflowMachine.ts"
      to: "src/main/voiceService.ts"
      via: "triggerAICall actor invokes initiateScreeningCall"
      pattern: "initiateScreeningCall"
    - from: "src/main/voicePoller.ts"
      to: "src/main/workflowService.ts"
      via: "reportScreeningComplete on call completion"
      pattern: "reportScreeningComplete"
---

<objective>
Integrate ElevenLabs Conversational AI for outbound screening calls with polling-based status retrieval.

Purpose: Enable the workflow engine to initiate AI voice calls when candidates reach the screening state. Since this is a desktop app that cannot receive webhooks, we use polling to retrieve call status and transcripts from ElevenLabs.

Output: Voice service with ElevenLabs SDK, polling infrastructure, database schema for screening, and workflow machine integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-ai-voice-screening/11-CONTEXT.md
@.planning/phases/11-ai-voice-screening/11-RESEARCH.md
@.planning/phases/10-outreach-workflow-engine/10-01-SUMMARY.md
@src/main/workflowMachine.ts
@src/main/workflowService.ts
@src/main/credentialManager.ts
@src/main/database.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install ElevenLabs SDK and add database migration v9</name>
  <files>
    - package.json
    - src/main/database.ts
  </files>
  <action>
    Install ElevenLabs TypeScript SDK:
    ```bash
    npm install @elevenlabs/client
    ```

    Add database migration v9 in the runMigrations function (after existing v7/v8):

    ```sql
    -- Migration v9: Voice screening tables

    -- Screening scripts per project (optional override)
    CREATE TABLE IF NOT EXISTS screening_scripts (
      id TEXT PRIMARY KEY,
      project_id TEXT NOT NULL,
      agent_name TEXT DEFAULT 'Alex',
      system_prompt_override TEXT,
      first_message_override TEXT,
      criteria_json TEXT,  -- ScreeningCriteria JSON object
      created_at TEXT NOT NULL,
      updated_at TEXT NOT NULL,
      FOREIGN KEY (project_id) REFERENCES projects(id) ON DELETE CASCADE
    );

    CREATE INDEX IF NOT EXISTS idx_screening_scripts_project ON screening_scripts(project_id);

    -- Add retry and voicemail tracking to call_records
    ALTER TABLE call_records ADD COLUMN attempt_number INTEGER DEFAULT 1;
    ALTER TABLE call_records ADD COLUMN max_attempts INTEGER DEFAULT 3;
    ALTER TABLE call_records ADD COLUMN next_retry_at TEXT;
    ALTER TABLE call_records ADD COLUMN failure_reason TEXT;
    ALTER TABLE call_records ADD COLUMN was_voicemail INTEGER DEFAULT 0;
    ALTER TABLE call_records ADD COLUMN voicemail_message_left INTEGER DEFAULT 0;
    ALTER TABLE call_records ADD COLUMN extracted_data_json TEXT;

    -- Index for retry queue
    CREATE INDEX IF NOT EXISTS idx_call_records_retry ON call_records(next_retry_at) WHERE status = 'no_answer';
    ```

    Note: Use try-catch for ALTER TABLE statements since SQLite doesn't support "IF NOT EXISTS" for columns. Check if column exists first using PRAGMA table_info.

  </action>
  <verify>
    Run `npm ls @elevenlabs/client` to confirm installation.
    Run `npm run typecheck` to confirm no type errors.
    App starts without database errors.
  </verify>
  <done>
    ElevenLabs SDK installed; screening_scripts table and call_records columns exist in database.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create voice service with ElevenLabs integration</name>
  <files>
    - src/main/voiceService.ts
    - src/main/credentialManager.ts
  </files>
  <action>
    First, extend credentialManager.ts to support ElevenLabs credentials:

    1. Add to ProviderType: `"elevenlabs"`
    2. Add ElevenLabsCredentialType: `"api_key" | "screening_agent_id" | "phone_number_id"`
    3. Update CredentialType union to include ElevenLabsCredentialType

    Then create src/main/voiceService.ts:

    ```typescript
    /**
     * Voice Service - Phase 11 AI Voice Screening
     *
     * Integrates with ElevenLabs Conversational AI for outbound screening calls.
     * Uses polling to retrieve call status (desktop app constraint - no webhooks).
     */

    import { ElevenLabsClient } from '@elevenlabs/client';
    import { getCredential } from './credentialManager';
    import { getDatabase } from './database';
    import crypto from 'crypto';

    // Types
    interface OutboundCallParams {
      candidateId: string;
      projectId: string;
      phoneNumber: string;
      candidateName: string;
      roleTitle: string;
      companyName?: string;
      salaryRange?: { min: number; max: number };
      location?: string;
      priorMessaging?: string;
    }

    interface OutboundCallResult {
      success: boolean;
      conversationId?: string;
      callRecordId?: string;
      error?: string;
    }

    interface CallStatusResult {
      status: 'pending' | 'in_progress' | 'completed' | 'failed' | 'no_answer';
      transcript?: string;
      durationSeconds?: number;
      analysis?: {
        callSuccessful: boolean;
        transcriptSummary: string;
        dataCollectionResults?: Record<string, unknown>;
      };
    }

    /**
     * Create ElevenLabs client with stored API key.
     */
    function getElevenLabsClient(): ElevenLabsClient | null {
      const apiKey = getCredential(null, 'elevenlabs', 'api_key');
      if (!apiKey) {
        console.warn('[VoiceService] No ElevenLabs API key configured');
        return null;
      }
      return new ElevenLabsClient({ apiKey });
    }

    /**
     * Build dynamic variables for ElevenLabs agent personalization.
     * Per RESEARCH.md: candidate name, role, company, salary, location, prior context
     */
    function buildDynamicVariables(params: OutboundCallParams): Record<string, string> {
      const vars: Record<string, string> = {
        candidate_name: params.candidateName,
        candidate_first_name: params.candidateName.split(' ')[0],
        role_title: params.roleTitle,
        company_name: params.companyName || 'our client',
      };

      if (params.salaryRange) {
        vars.salary_min = params.salaryRange.min.toLocaleString();
        vars.salary_max = params.salaryRange.max.toLocaleString();
      }
      if (params.location) {
        vars.job_location = params.location;
      }
      if (params.priorMessaging) {
        vars.prior_context = params.priorMessaging;
      }

      return vars;
    }

    /**
     * Initiate an outbound screening call via ElevenLabs + Twilio.
     * Per CONTEXT.md: 2-3 minute pre-screening call gathering logistics.
     */
    export async function initiateScreeningCall(
      params: OutboundCallParams
    ): Promise<OutboundCallResult> {
      const client = getElevenLabsClient();
      if (!client) {
        return { success: false, error: 'ElevenLabs credentials not configured' };
      }

      const agentId = getCredential(params.projectId, 'elevenlabs', 'screening_agent_id')
        || getCredential(null, 'elevenlabs', 'screening_agent_id');
      const phoneNumberId = getCredential(params.projectId, 'elevenlabs', 'phone_number_id')
        || getCredential(null, 'elevenlabs', 'phone_number_id');

      if (!agentId || !phoneNumberId) {
        return { success: false, error: 'ElevenLabs agent or phone number not configured' };
      }

      try {
        const dynamicVariables = buildDynamicVariables(params);

        // ElevenLabs Twilio outbound call API
        // Note: API shape may vary - check @elevenlabs/client types
        const response = await client.conversationalAi.twilio.outboundCall({
          agent_id: agentId,
          agent_phone_number_id: phoneNumberId,
          to_number: params.phoneNumber,
          conversation_initiation_client_data: {
            dynamic_variables: dynamicVariables,
          },
        });

        if (!response.success) {
          return { success: false, error: response.message || 'Call initiation failed' };
        }

        // Create call record in database
        const db = getDatabase();
        const callId = crypto.randomUUID();
        const now = new Date().toISOString();

        db.prepare(`
          INSERT INTO call_records (
            id, project_id, cv_id, type, status, provider_call_id, phone_number,
            started_at, created_at, attempt_number
          ) VALUES (?, ?, ?, 'screening', 'in_progress', ?, ?, ?, ?, 1)
        `).run(
          callId,
          params.projectId,
          params.candidateId,
          response.conversationId || response.callSid || null,
          params.phoneNumber,
          now,
          now
        );

        console.log(`[VoiceService] Initiated screening call for ${params.candidateId}: ${response.conversationId}`);

        return {
          success: true,
          conversationId: response.conversationId || response.callSid || undefined,
          callRecordId: callId,
        };
      } catch (error) {
        console.error('[VoiceService] Failed to initiate call:', error);
        return {
          success: false,
          error: error instanceof Error ? error.message : 'Unknown error',
        };
      }
    }

    /**
     * Get call status from ElevenLabs API (polling approach).
     * Desktop apps cannot receive webhooks, so we poll for status.
     */
    export async function getCallStatus(conversationId: string): Promise<CallStatusResult | null> {
      const client = getElevenLabsClient();
      if (!client) return null;

      try {
        // Get conversation details from ElevenLabs
        // Note: Check @elevenlabs/client for actual method name
        const conversation = await client.conversationalAi.getConversation({
          conversation_id: conversationId,
        });

        if (!conversation) {
          return null;
        }

        // Map ElevenLabs status to our status
        let status: CallStatusResult['status'] = 'pending';
        if (conversation.status === 'in_progress' || conversation.status === 'processing') {
          status = 'in_progress';
        } else if (conversation.status === 'done' || conversation.status === 'completed') {
          status = 'completed';
        } else if (conversation.status === 'failed') {
          status = 'failed';
        } else if (conversation.status === 'no_answer') {
          status = 'no_answer';
        }

        // Format transcript if available
        let transcript: string | undefined;
        if (conversation.transcript && Array.isArray(conversation.transcript)) {
          transcript = conversation.transcript
            .map((t: { role: string; message: string }) =>
              `${t.role === 'agent' ? 'Agent' : 'Candidate'}: ${t.message}`
            )
            .join('\n\n');
        }

        return {
          status,
          transcript,
          durationSeconds: conversation.metadata?.call_duration_secs,
          analysis: conversation.analysis ? {
            callSuccessful: conversation.analysis.call_successful === 'true',
            transcriptSummary: conversation.analysis.transcript_summary || '',
            dataCollectionResults: conversation.analysis.data_collection_results,
          } : undefined,
        };
      } catch (error) {
        console.error('[VoiceService] Failed to get call status:', error);
        return null;
      }
    }

    /**
     * Check if voice calling is configured for a project.
     */
    export function isVoiceConfigured(projectId: string | null): boolean {
      const apiKey = getCredential(null, 'elevenlabs', 'api_key');
      const agentId = getCredential(projectId, 'elevenlabs', 'screening_agent_id')
        || getCredential(null, 'elevenlabs', 'screening_agent_id');
      const phoneNumberId = getCredential(projectId, 'elevenlabs', 'phone_number_id')
        || getCredential(null, 'elevenlabs', 'phone_number_id');

      return !!(apiKey && agentId && phoneNumberId);
    }
    ```

    Note: The actual ElevenLabs SDK API shape may differ - check the installed package types and adjust accordingly. The key patterns are:
    - Client initialization with API key
    - Outbound call with agent_id, phone_number_id, dynamic_variables
    - Polling for conversation status

  </action>
  <verify>
    `npm run typecheck` passes (or only pre-existing errors).
    voiceService.ts exports initiateScreeningCall, getCallStatus, isVoiceConfigured.
    Verify credentialManager.ts has ElevenLabsCredentialType:
    ```bash
    grep -q "elevenlabs" src/main/credentialManager.ts && echo "ElevenLabs provider added" || echo "MISSING"
    grep -q "api_key.*screening_agent_id\|screening_agent_id.*api_key" src/main/credentialManager.ts && echo "ElevenLabs credential types added" || echo "MISSING"
    ```
  </verify>
  <done>
    Voice service can initiate ElevenLabs calls and poll for status.
    credentialManager.ts supports elevenlabs provider with api_key, screening_agent_id, phone_number_id credential types.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create voice poller and wire to workflow machine</name>
  <files>
    - src/main/voicePoller.ts
    - src/main/workflowMachine.ts
    - src/main/index.ts
    - src/main/preload.ts
  </files>
  <action>
    Create src/main/voicePoller.ts - polls for in-progress call status:

    ```typescript
    /**
     * Voice Poller - Phase 11 AI Voice Screening
     *
     * Polls ElevenLabs for call status updates.
     * Desktop apps cannot receive webhooks, so we poll.
     */

    import { getDatabase } from './database';
    import { getCallStatus } from './voiceService';
    import { reportScreeningComplete, getWorkflowActor } from './workflowService';

    const POLL_INTERVAL_MS = 10_000; // 10 seconds (calls are 2-3 minutes)
    let pollIntervalId: NodeJS.Timeout | null = null;

    interface InProgressCall {
      id: string;
      cv_id: string;
      provider_call_id: string;
    }

    /**
     * Poll for in-progress calls and update status.
     */
    async function pollCallStatuses(): Promise<void> {
      const db = getDatabase();

      // Get all in-progress screening calls
      const inProgressCalls = db.prepare(`
        SELECT id, cv_id, provider_call_id
        FROM call_records
        WHERE status = 'in_progress' AND type = 'screening' AND provider_call_id IS NOT NULL
      `).all() as InProgressCall[];

      if (inProgressCalls.length === 0) return;

      console.log(`[VoicePoller] Polling ${inProgressCalls.length} in-progress calls`);

      for (const call of inProgressCalls) {
        try {
          const status = await getCallStatus(call.provider_call_id);

          if (!status) continue;

          if (status.status === 'completed' || status.status === 'failed' || status.status === 'no_answer') {
            const now = new Date().toISOString();

            // Update call record
            db.prepare(`
              UPDATE call_records SET
                status = ?,
                duration_seconds = ?,
                ended_at = ?
              WHERE id = ?
            `).run(status.status, status.durationSeconds || 0, now, call.id);

            // Store transcript if available
            if (status.transcript) {
              const transcriptId = crypto.randomUUID();
              db.prepare(`
                INSERT INTO transcripts (id, call_id, project_id, raw_text, summary, created_at)
                SELECT ?, ?, project_id, ?, ?, ?
                FROM call_records WHERE id = ?
              `).run(
                transcriptId,
                call.id,
                status.transcript,
                status.analysis?.transcriptSummary || null,
                now,
                call.id
              );
            }

            // Report to workflow - for now, treat completed calls as needing analysis
            // Plan 11-03 will add Claude-based pass/fail determination
            if (status.status === 'completed' && call.cv_id) {
              // Mark as needs analysis - workflow stays in screening until analyzed
              console.log(`[VoicePoller] Call ${call.id} completed, transcript stored`);
              // Note: Don't call reportScreeningComplete yet - Plan 11-03 adds analysis
            } else if (status.status === 'failed' || status.status === 'no_answer') {
              // Call failed - report failure to workflow
              if (call.cv_id && getWorkflowActor(call.cv_id)) {
                reportScreeningComplete(call.cv_id, 'failed');
              }
            }
          }
        } catch (error) {
          console.error(`[VoicePoller] Error polling call ${call.id}:`, error);
        }
      }
    }

    /**
     * Start the voice poller.
     */
    export function startVoicePoller(): void {
      if (pollIntervalId) {
        console.warn('[VoicePoller] Already running');
        return;
      }

      console.log('[VoicePoller] Starting with interval', POLL_INTERVAL_MS, 'ms');
      pollIntervalId = setInterval(pollCallStatuses, POLL_INTERVAL_MS);

      // Run immediately
      pollCallStatuses();
    }

    /**
     * Stop the voice poller.
     */
    export function stopVoicePoller(): void {
      if (pollIntervalId) {
        clearInterval(pollIntervalId);
        pollIntervalId = null;
        console.log('[VoicePoller] Stopped');
      }
    }
    ```

    Add missing import at top of voicePoller.ts:
    ```typescript
    import crypto from 'crypto';
    ```

    Update workflowMachine.ts - replace the placeholder triggerAICall actor:

    ```typescript
    // Import at top of file
    import { initiateScreeningCall, isVoiceConfigured } from './voiceService';

    // Update the triggerAICall actor:
    triggerAICall: fromPromise(
      async ({ input }: { input: WorkflowContext }) => {
        if (!input.phone) {
          throw new Error('No phone number available for AI call');
        }

        const result = await initiateScreeningCall({
          candidateId: input.candidateId,
          projectId: input.projectId,
          phoneNumber: input.phone,
          candidateName: input.candidateName,
          roleTitle: 'Open Position', // TODO: Get from project/JD in Plan 11-02
          companyName: undefined, // TODO: Get from project settings
        });

        if (!result.success) {
          throw new Error(result.error || 'Failed to initiate screening call');
        }

        return {
          callId: result.callRecordId,
          conversationId: result.conversationId,
          status: 'initiated',
        };
      },
    ),

    // Update aiCallEnabled guard to check actual configuration:
    aiCallEnabled: ({ context }) => {
      return isVoiceConfigured(context.projectId);
    },
    ```

    Update src/main/index.ts:
    - Import startVoicePoller, stopVoicePoller from voicePoller
    - Call startVoicePoller() after initializeWorkflows() in app.whenReady
    - Call stopVoicePoller() before stopAllWorkflows() in app will-quit

    Add IPC handlers for voice configuration check:
    ```typescript
    ipcMain.handle('is-voice-configured', (_event, projectId: string | null) => {
      return isVoiceConfigured(projectId);
    });
    ```

    Update src/main/preload.ts:
    ```typescript
    isVoiceConfigured: (projectId: string | null) => ipcRenderer.invoke('is-voice-configured', projectId),
    ```

  </action>
  <verify>
    `npm run typecheck` passes.
    App starts and VoicePoller logs "Starting with interval".
    Workflow machine's aiCallEnabled guard returns false when credentials not set.
  </verify>
  <done>
    Voice poller polls for call status; workflow machine triggers real ElevenLabs calls when configured.
  </done>
</task>

</tasks>

<verification>
Run these commands to verify the plan is complete:

```bash
# TypeScript compiles
npm run typecheck

# Tests pass (existing tests, no new tests in this plan)
npm test

# ElevenLabs SDK installed
npm ls @elevenlabs/client

# New files exist
ls src/main/voiceService.ts src/main/voicePoller.ts

# Database migration runs (check logs on app start)
npm start
```

Verify in the app:

1. App starts without errors
2. Console shows "[VoicePoller] Starting with interval"
3. Without ElevenLabs credentials, aiCallEnabled guard returns false (workflow won't auto-escalate to screening)
   </verification>

<success_criteria>

- ElevenLabs SDK (@elevenlabs/client) installed
- voiceService.ts exports initiateScreeningCall, getCallStatus, isVoiceConfigured
- voicePoller.ts starts on app ready and polls for in-progress calls
- workflowMachine.ts triggerAICall actor calls initiateScreeningCall
- aiCallEnabled guard checks actual credential configuration
- Database has screening_scripts table and call_records retry columns
- credentialManager supports elevenlabs provider type
  </success_criteria>

<output>
After completion, create `.planning/phases/11-ai-voice-screening/11-01-SUMMARY.md`
</output>
